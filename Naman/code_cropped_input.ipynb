{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom random import choice\nfrom skimage import io\nimport sklearn.metrics\n\nfrom tqdm.notebook import tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.752105,"end_time":"2021-04-22T12:22:27.541526","exception":false,"start_time":"2021-04-22T12:22:24.789421","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    BATCH_SIZE = 64\n    EPOCHS = 250\n    LEARNING_RATE = 3e-4","metadata":{"papermill":{"duration":0.032907,"end_time":"2021-04-22T12:22:27.599908","exception":false,"start_time":"2021-04-22T12:22:27.567001","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = '../input/dlcv-2021-hackathon/train/train/'\nTEST_PATH = '../input/dlcv-2021-hackathon/test/'\nsample_csv = pd.read_csv('../input/dlcv-2021-hackathon/sample_submission.csv')\ntest_csv = pd.read_csv('../input/dlcv-2021-hackathon/test.csv')","metadata":{"papermill":{"duration":0.084868,"end_time":"2021-04-22T12:22:27.709512","exception":false,"start_time":"2021-04-22T12:22:27.624644","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Storing File_Names\n\nlst = os.listdir(TRAIN_PATH+'Post')\nfilenames = [file[5:] for file in lst]\nprint(len(filenames))","metadata":{"papermill":{"duration":0.104292,"end_time":"2021-04-22T12:22:27.838721","exception":false,"start_time":"2021-04-22T12:22:27.734429","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Custom_Dataset(Dataset):\n   \n    def __init__(self, TRAIN_PATH, filenames, transform=None):\n        \n        self.filenames = filenames\n        self.post_op_path = TRAIN_PATH + \"Post/\"\n        self.pre_op_path = TRAIN_PATH + \"Pre/\" \n        self.transform = transform\n        df_columns = ['post_name', 'pre_name', 'label']\n        self.df = pd.DataFrame(columns=df_columns)\n        \n        for i in range(len(filenames)):\n            label = 1\n            post_fn = \"POST_\"+filenames[i]\n            pre_fn_true = \"PRE_\"+filenames[i]\n            self.df = self.df.append(pd.Series([post_fn, pre_fn_true, label], index=self.df.columns), ignore_index=True)\n\n            label=0\n            rand_idx = choice([j for j in range(len(filenames)) if j not in [i]])\n            pre_fn_false = \"PRE_\"+filenames[rand_idx]\n            self.df = self.df.append(pd.Series([post_fn, pre_fn_false, label], index=self.df.columns), ignore_index=True)\n            \n        \n    def __len__(self):\n        return len(self.df)\n    \n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        post_name = row['post_name']\n        pre_name = row['pre_name']\n        label = row['label']\n        \n        post_img = Image.fromarray(io.imread(self.post_op_path+post_name))\n        pre_img = Image.fromarray(io.imread(self.pre_op_path+pre_name))\n        n, m = post_img.size\n\n        post_img = post_img.crop((0, 0, n, int(m*3/4)))\n        pre_img = pre_img.crop((0, 0, n, int(m*3/4)))\n        \n        \n#         post_img = Image.fromarray(post_img.transpose(2,0,1))\n#         pre_img = Image.fromarray(pre_img.transpose(2,0,1))        \n#         post_img = np.array(Image.open(self.post_op_path+post_name),\n#         pre_img = Image.open(self.pre_op_path+pre_name) \n        \n        if self.transform:\n#             print(type(post_img))\n            post_img = self.transform(post_img)\n            pre_img = self.transform(pre_img)\n        \n        return post_img, pre_img, label","metadata":{"papermill":{"duration":0.031118,"end_time":"2021-04-22T12:22:27.894872","exception":false,"start_time":"2021-04-22T12:22:27.863754","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1, img2 = test_csv.iloc[0].item().split(',')\nimg1 = img1.strip()\nimg2 = img2.strip()\n\nprint(img1, img2)\nimg1 = Image.fromarray(io.imread(TEST_PATH+img1))\nimg1","metadata":{"papermill":{"duration":0.202137,"end_time":"2021-04-22T12:22:28.114131","exception":false,"start_time":"2021-04-22T12:22:27.911994","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test_Dataset(Dataset):\n   \n    def __init__(self, TEST_PATH, test_csv, transform=None):\n        \n        self.img_path = TEST_PATH\n        self.transform = transform\n        \n    def __len__(self):\n        return len(test_csv)\n    \n    \n    def __getitem__(self, idx):\n        img1_name, img2_name = test_csv.iloc[idx].item().split(',')\n        img1_name = img1_name.strip()\n        img2_name = img2_name.strip()\n        \n        img1 = Image.fromarray(io.imread(self.img_path+img1_name))\n        img2 = Image.fromarray(io.imread(self.img_path+img2_name))\n        \n        n, m = img1.size\n\n        img1 = img1.crop((0, 0, n, int(m*3/4)))\n        img2 = img2.crop((0, 0, n, int(m*3/4)))\n        \n        if self.transform:\n#             print(type(post_img))\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n        \n        return img1, img2","metadata":{"papermill":{"duration":0.033523,"end_time":"2021-04-22T12:22:28.171533","exception":false,"start_time":"2021-04-22T12:22:28.13801","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_size = 90\ntrain_size = int((80/100) * len(filenames))\ntrain_dataset = Custom_Dataset(TRAIN_PATH, filenames[:train_size], transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True)\n\nval_dataset = Custom_Dataset(TRAIN_PATH, filenames[train_size:], transform=transform)\nval_dataloader = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE*2, shuffle=False)","metadata":{"papermill":{"duration":5.060615,"end_time":"2021-04-22T12:22:33.25565","exception":false,"start_time":"2021-04-22T12:22:28.195035","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n#     transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_dataset = Test_Dataset(TEST_PATH, test_csv, transform=test_transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE*2, shuffle=False)","metadata":{"papermill":{"duration":0.031492,"end_time":"2021-04-22T12:22:33.311945","exception":false,"start_time":"2021-04-22T12:22:33.280453","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataLoader Sanity check","metadata":{"papermill":{"duration":0.023433,"end_time":"2021-04-22T12:22:33.359373","exception":false,"start_time":"2021-04-22T12:22:33.33594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"post_img, pre_img, label = next(iter(train_dataloader))\nprint(post_img.shape)\npost_img = post_img.numpy()\npre_img = pre_img.numpy()\nshow = 5\n\n\nfig, ax = plt.subplots(5, 2, figsize=(14,14))\nfor i in range(5):\n    ax[i][0].imshow(post_img[i].transpose(1,2,0))\n    ax[i][0].set_title('Post Operation Label: '+str(label[i]))\n    ax[i][0].axis('off')\n\n    ax[i][1].imshow(pre_img[i].transpose(1,2,0))\n    ax[i][1].set_title('Pre Operation label: '+str(label[i]))\n    ax[i][1].axis('off')\n    \n\nplt.show()\n","metadata":{"papermill":{"duration":4.105462,"end_time":"2021-04-22T12:22:37.488197","exception":false,"start_time":"2021-04-22T12:22:33.382735","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_up = models.resnet18(pretrained=True)\nmodel_dn = models.resnet18(pretrained=True)","metadata":{"papermill":{"duration":2.847002,"end_time":"2021-04-22T12:22:40.366022","exception":false,"start_time":"2021-04-22T12:22:37.51902","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_up)","metadata":{"papermill":{"duration":0.070679,"end_time":"2021-04-22T12:22:40.478558","exception":false,"start_time":"2021-04-22T12:22:40.407879","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FF_layer_up = [model_up.classifier[i] for i in [0,3,6]]\n# FF_layer_dn = [model_dn.classifier[i] for i in [0,3,6]]\n\nfor model in [model_up, model_dn]:\n    for params in model.parameters():\n        params.requires_grad = False\n        \n# for i in [0,3,6]:\n#     model_up.classifier[i] = FF_layer_up[i//3]\n#     model_dn.classifier[i] = FF_layer_dn[i//3]    \n\n# print(model_up)\n\n# model_up.classifier = nn.Sequential(\n#     nn.Linear(in_features=25088, out_features=4096, bias=True),\n#     nn.ReLU(inplace=True),\n#     nn.Dropout(p=0.5, inplace=False),\n#     nn.Linear(in_features=4096, out_features=64, bias=True),\n# #     nn.ReLU(inplace=True),\n# #     nn.ReLU(inplace=True),\n# #     nn.Dropout(p=0.5, inplace=False),\n# #     nn.Linear(in_features=4096, out_features=1000, bias=True)\n# )\n\n# model_dn.classifier = nn.Sequential(\n#     nn.Linear(in_features=25088, out_features=4096, bias=True),\n#     nn.ReLU(inplace=True),\n#     nn.Dropout(p=0.5, inplace=False),\n#     nn.Linear(in_features=4096, out_features=64, bias=True),\n# #     nn.ReLU(inplace=True),\n# #     nn.ReLU(inplace=True),\n# #     nn.Dropout(p=0.5, inplace=False),\n# #     nn.Linear(in_features=4096, out_features=1000, bias=True)\n# )\n\nmodel_up.fc = nn.Linear(512,256)\nmodel_dn.fc = nn.Linear(512,256)\n\nprint(model_up)","metadata":{"papermill":{"duration":0.07413,"end_time":"2021-04-22T12:22:40.604127","exception":false,"start_time":"2021-04-22T12:22:40.529997","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class My_Model(nn.Module):\n    def __init__(self, model_up, model_dn):\n        super().__init__()\n        self.model_up = model_up\n        self.model_dn = model_dn\n        \n        self.linear1 = nn.Linear(512, 512)\n        self.linear2 = nn.Linear(512, 2)\n        self.softmax = nn.Softmax(dim=1)\n        self.dropout = nn.Dropout()\n        self.relu = nn.ReLU()\n        \n    def forward(self, post_img, pre_img):\n        final_up = self.model_up(post_img)\n#         print('final_up : ', final_up.shape)\n        final_dn = self.model_dn(pre_img)   \n#         print('final_dn : ', final_dn.shape)\n        \n        x = torch.cat((final_up, final_dn),1)\n#         print(x.shape)\n        x = self.relu(self.linear1(x))\n#        x = self.dropout(x)\n        x = self.linear2(x)\n        x = self.softmax(x)\n        return x\n        ","metadata":{"papermill":{"duration":0.066376,"end_time":"2021-04-22T12:22:40.721221","exception":false,"start_time":"2021-04-22T12:22:40.654845","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = My_Model(model_up, model_dn)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG.LEARNING_RATE)\n\ndef train(model, optimizer, criterion):\n    train_loss = []\n    eval_loss = []\n    macro_f1 = []\n    for epoch in tqdm(range(CFG.EPOCHS)):\n        train_loss_per_epoch = 0\n        model.train()\n        true_labels = []\n        pred_labels = []\n        \n        for post_img, pre_img, labels in train_dataloader:\n            post_img = post_img.to(device)\n            pre_img = pre_img.to(device)\n            labels = labels.to(device)\n            out = model(post_img, pre_img)\n            _, pred = torch.max(out, axis=1)\n            \n            loss = criterion(out, labels)\n\n            train_loss_per_epoch += loss.item() / len(train_dataloader)\n            \n            true_labels.append(labels.cpu().numpy())\n            pred_labels.append(pred.cpu().numpy())\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        train_loss.append(train_loss_per_epoch)\n        model.eval()\n        with torch.no_grad():\n            val_loss_per_epoch = 0\n            for post_img, pre_img, labels in val_dataloader:\n                post_img = post_img.to(device)\n                pre_img = pre_img.to(device)\n                labels = labels.to(device)\n                out = model(post_img, pre_img)\n                loss = criterion(out, labels)\n                \n                val_loss_per_epoch += loss.item() / len(val_dataloader)\n                \n        eval_loss.append(val_loss_per_epoch)\n        \n        true_labels = np.concatenate(true_labels)\n        pred_labels = np.concatenate(pred_labels) \n        macro_f1_per_epoch = sklearn.metrics.f1_score(true_labels, pred_labels)\n        macro_f1.append(macro_f1_per_epoch)\n        \n        print(f\"EPOCH: {epoch+1}\\tTRAIN_LOSS: {train_loss_per_epoch}\\tVAL_LOSS: {val_loss_per_epoch}\\tMACRO_F1: {macro_f1_per_epoch}\")\n        \n    return train_loss, eval_loss, macro_f1\n        \n        ","metadata":{"papermill":{"duration":4.364449,"end_time":"2021-04-22T12:22:45.136407","exception":false,"start_time":"2021-04-22T12:22:40.771958","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, eval_loss, macro_f1 = train(model, optimizer, criterion)","metadata":{"papermill":{"duration":7292.373926,"end_time":"2021-04-22T14:24:17.541349","exception":false,"start_time":"2021-04-22T12:22:45.167423","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss, label='Train')\nplt.plot(eval_loss, label='Eval')\nplt.show()","metadata":{"papermill":{"duration":0.227214,"end_time":"2021-04-22T14:24:17.850876","exception":false,"start_time":"2021-04-22T14:24:17.623662","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(macro_f1)\nplt.show()","metadata":{"papermill":{"duration":0.215274,"end_time":"2021-04-22T14:24:18.149157","exception":false,"start_time":"2021-04-22T14:24:17.933883","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\n\ndef inference(model):\n    model.eval()\n    with torch.no_grad():\n        predictions = []\n        for img1, img2 in tqdm(test_dataloader):\n            img1 = img1.to(device)\n            img2 = img2.to(device)\n            out = model(img1, img2)\n            scores.append(out.cpu().numpy())\n            _, pred = torch.max(out, 1)\n#             print(pred.cpu().numpy())\n            predictions.append(pred.cpu().numpy())\n\n    return predictions, scores\n","metadata":{"papermill":{"duration":0.094573,"end_time":"2021-04-22T14:24:18.330054","exception":false,"start_time":"2021-04-22T14:24:18.235481","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, scores = inference(model)","metadata":{"papermill":{"duration":94.601561,"end_time":"2021-04-22T14:25:53.01427","exception":false,"start_time":"2021-04-22T14:24:18.412709","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = np.concatenate(predictions)\ntest_pred.shape","metadata":{"papermill":{"duration":0.095107,"end_time":"2021-04-22T14:25:53.208696","exception":false,"start_time":"2021-04-22T14:25:53.113589","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = test_csv.copy()\ntmp[['0','1']] = np.concatenate(scores)\ntmp.to_csv('Predictions_crop.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv['Predicted'] = test_pred","metadata":{"papermill":{"duration":0.097109,"end_time":"2021-04-22T14:25:53.39088","exception":false,"start_time":"2021-04-22T14:25:53.293771","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv.to_csv('Submission.csv', index=False)","metadata":{"papermill":{"duration":0.252551,"end_time":"2021-04-22T14:25:53.730613","exception":false,"start_time":"2021-04-22T14:25:53.478062","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"papermill":{"duration":0.21982,"end_time":"2021-04-22T14:25:54.034549","exception":false,"start_time":"2021-04-22T14:25:53.814729","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.086874,"end_time":"2021-04-22T14:25:54.208747","exception":false,"start_time":"2021-04-22T14:25:54.121873","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}